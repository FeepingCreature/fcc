module std.unicode;

class UnicodeError : Error {
  void init(string s) super.init "UnicodeError: $s";
}

class UTF8Iterator : Iterator!string {
  string back;
  void init(string s) { back = s; }
  bool advance() {
    pragma(fast);
    if (!back.length) return false;
    auto peek = back[0];
    int size;
    if (peek < 0b1000_0000) size = 1;
    else if (peek < 0b1110_0000) size = 2;
    else if (peek < 0b1111_0000) size = 3;
    else if (peek < 0b1111_1000) size = 4;
    else if (peek < 0b1111_1100) size = 5;
    else if (peek < 0b1111_1110) size = 6;
    else raise new UnicodeError "Invalid UTF-8 sequence";
    if (size > back.length)
      raise new UnicodeError "Out of data in mid-sequence";
    (value, back) = back[(0..size, size..$)];
    return true;
  }
}

class UTF8Decoder : Iterator!int {
  UTF8Iterator back;
  void init(string s) { back = new UTF8Iterator s; }
  void free() { back.free; super.free(); }
  bool advance() {
    if (!back.advance()) return false;
    auto s = back.value;
    if (s.length == 1) {
      value = s[0];
    } else if (s.length == 2) {
      value = (s[0] & 0b0001_1111) << 6 | (s[1] & 0b0011_1111);
    } else if (s.length == 3) {
      value = (s[0] & 0b0000_1111) << 12 | (s[1] & 0b0011_1111) << 6 | (s[2] & 0b0011_1111);
    } else {
      writeln "help how do I decode utf8 length $(s.length) $(ubyte[]: s)";
      fail;
    }
    return true;
  }
}
